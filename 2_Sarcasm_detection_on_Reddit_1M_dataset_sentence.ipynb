{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_XjNG35q-_c"
   },
   "source": [
    "# **Sarcasm detection on Reddit**\n",
    "\n",
    "In this notebook, we addressed a binary classification problem aimed at detecting sarcasm in Reddit comments.\n",
    "\n",
    "We chose 3 feature engineering methods and 4 classification models and compared them to find out which combination performs better:\n",
    "- Feature engineering: TF-IDF, Word2Vec, and BERT.\n",
    "\n",
    "- Classification models: Logistic regression, Random forest, Linear SVC, and Multilayer perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MxG9URvZX6F"
   },
   "source": [
    "## **Spark Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rr7839FTJ7RR"
   },
   "source": [
    "### 1. Install PySpark and related dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_m0ZZHdpAL1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# java\n",
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget -q https://downloads.apache.org/spark/spark-3.2.4/spark-3.2.4-bin-hadoop2.7.tgz\n",
    "# !tar xf spark-3.2.4-bin-hadoop2.7.tgz\n",
    "# !rm -rf /content/spark-3.2.4-bin-hadoop2.7.tgz\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTWh4NkcrFqF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Krt1RPb1rK53",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting java path as environment variable\n",
    "# import os\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GX32q-n1rLbb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pyspark\n",
    "!pip install spark-nlp==4.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZT5w4kaYGcZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kw7DLnymt5lD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pyspark --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAJfhtqAgHep"
   },
   "source": [
    "### 2. Import useful Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNwfUBoUgNLP"
   },
   "outputs": [],
   "source": [
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.feature import VectorAssembler, SQLTransformer, Normalizer\n",
    "from pyspark.sql.functions import udf, col, lower, trim, regexp_replace, transform\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7SUuHFUgfhs"
   },
   "source": [
    "### 3. Create Spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ak2WG_p3uaIi"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Hj0MDQTghZ0"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"1g\") \\\n",
    "    .config(\"spark.driver.memory\",\"32G\") \\\n",
    "    .config(\"spark.python.worker.memory\",\"32G\") \\\n",
    "    .config(\"spark.sql.analyzer.maxIterations\", \"6000\") \\\n",
    "    .config(\"spark.driver.cores\", \"10\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"32G\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.4.2\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi0BzByXufxI"
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "type(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvgLAqZqvG5L"
   },
   "source": [
    "## **Dataset**\n",
    "\n",
    "The original dataset used for this task is available [here](https://www.kaggle.com/datasets/danofer/sarcasm).\n",
    "This dataset contains 1.3 million Sarcastic comments from the Internet commentary website Reddit.\n",
    "The dataset was generated by scraping comments from Reddit containing the `\\s` (sarcasm) tag. This tag is often used by Redditors to indicate that their comment is in jest and not meant to be taken seriously, and is generally a reliable indicator of sarcastic comment content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSWbPHmjuCBS"
   },
   "source": [
    "### Download dataset from Kaggle\n",
    "\n",
    "In order to get the dataset from Kaggle library, a kaggle.json file is required. It can be downloaded from our personal account page and uploaded in the same folder of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FqfesOeZ2li"
   },
   "outputs": [],
   "source": [
    "# Install the Kaggle library\n",
    "! pip install kaggle\n",
    "\n",
    "# Make a directory named “.kaggle”\n",
    "! mkdir kaggle\n",
    "\n",
    "# Copy the “kaggle.json” into this new directory\n",
    "! cp kaggle.json kaggle/\n",
    "\n",
    "# Allocate the required permission for this file.\n",
    "! chmod 600 kaggle/kaggle.json\n",
    "\n",
    "# Download the dataset\n",
    "! kaggle datasets download danofer/sarcasm -f train-balanced-sarcasm.csv\n",
    "\n",
    "# Unzip the directory\n",
    "! unzip train-balanced-sarcasm.csv.zip\n",
    "\n",
    "# Delete zip file\n",
    "! rm -rf train-balanced-sarcasm.csv.zip\n",
    "\n",
    "# Make a directory to save final models\n",
    "! mkdir models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfCVZgoavfcb"
   },
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_i1HuQ-rvKj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_file_path = \"train-balanced-sarcasm.csv\"):\n",
    "\n",
    "    df = spark.read.csv(\"train-balanced-sarcasm.csv\", header=True)\n",
    "\n",
    "    print(\"Dataframe size (n. of rows): {:d}\\n\".format(df.count()))\n",
    "    print(\"Dataframe schema:\")\n",
    "    df.printSchema()\n",
    "    df_from_csv.show(10)\n",
    "\n",
    "    df, second_partition = df.randomSplit([0.1, 0.9], seed = 42)\n",
    "    second_partition.unpersist()\n",
    "    del second_partition\n",
    "    \n",
    "    # selecting only the columns we are interested in\n",
    "    df = df.drop(\"author\", \"subreddit\", \"score\", \"ups\", \"downs\", \"date\", \"created_utc\", \"parent_comment\")\n",
    "\n",
    "    print(\"\\nSelecting only the columns we are interested in\")\n",
    "    print(\"Dataframe schema:\")\n",
    "    df.printSchema()\n",
    "    df.show(10)\n",
    "\n",
    "    print(\"Number of NULL entry/ies: {:d}\".format(df.where(col(\"comment\").isNull()).count()))\n",
    "    # remove NULL entry/ies\n",
    "    df = df.na.drop(subset=[\"comment\"])\n",
    "\n",
    "    print(\"Number of NULL labels: {:d}\\n\".format(df.where(col(\"label\").isNull()).count()))\n",
    "    # remove NULL labels\n",
    "    df = df.na.drop(subset=[\"label\"])\n",
    "\n",
    "    print(\"Let's verify our dataset is still balanced:\")\n",
    "    df.groupBy('label').count().show()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PM9hJLdTeceE"
   },
   "source": [
    "### Data Pre-processing\n",
    "\n",
    "Starting from the raw text data, we apply a standard NLP preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kw3sn1DBkdbW"
   },
   "outputs": [],
   "source": [
    "from sparknlp.base import Finisher, DocumentAssembler\n",
    "from sparknlp.annotator import (Tokenizer, LemmatizerModel, StopWordsCleaner)\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIr7_usce3z-"
   },
   "outputs": [],
   "source": [
    "def clean_text(df, column_name=\"comment\"):\n",
    "\n",
    "    # Clean text\n",
    "    print(\"***** Clean text *****\\n\")\n",
    "\n",
    "    cleaned_df = df.dropDuplicates([\"comment\", \"label\"])\n",
    "\n",
    "    # remove rows with same comments but different labels\n",
    "    cleaned_df_2 = cleaned_df.groupby(\"comment\").agg(count(\"comment\").alias(\"polletti\")).filter(col(\"polletti\")>1)\n",
    "    cleaned_df = cleaned_df.join(cleaned_df_2, [\"comment\"], 'left_anti')\n",
    "\n",
    "    cleaned_df_2.unpersist()\n",
    "    del cleaned_df_2\n",
    "\n",
    "    print(\"Let's verify our dataset is still balanced:\")\n",
    "    cleaned_df.groupBy('label').count().show()\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5A1iplQHqZt"
   },
   "source": [
    "## **Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgeXosep6Ibf"
   },
   "source": [
    "### **BERT**\n",
    "\n",
    "*Bidirectional Encoder Representations from Transformers* (BERT) is a state-of-the-art transformer-based model for natural language processing (NLP). It is designed to capture contextual information from text by using a deep bidirectional architecture.\n",
    "BERT generates contextualized word embeddings, known as BERT embeddings, which are pre-trained on large amounts of unlabeled text and then fine-tuned for specific NLP tasks.\n",
    "\n",
    "The BERT model used in this notebook provides a **sentence-level embedding** using the BERT architecture. It takes as input a sequence of sentences and outputs a single embedding vector representing the entire sentence. The model captures the contextual information of the entire sentence and produces a fixed-length representation that captures the overall meaning or sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNQqJBGEqovN"
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator import BertSentenceEmbeddings\n",
    "from sparknlp import EmbeddingsFinisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZ8kiiEcrvKl"
   },
   "outputs": [],
   "source": [
    "def bert_sentence_embedding(df, save_parquet=False):\n",
    "\n",
    "    # convert the text into a Spark-NLP annotator-ready form\n",
    "    documentAssembler = DocumentAssembler() \\\n",
    "     .setInputCol('comment') \\\n",
    "     .setOutputCol('document')\n",
    "\n",
    "    # sent_bert_base_uncased -> the model is imported from https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\n",
    "    embeddings = BertSentenceEmbeddings.pretrained(\"sent_bert_base_uncased\", \"en\") \\\n",
    "                .setInputCols(\"document\") \\\n",
    "                .setOutputCol(\"embeddings\")\n",
    "\n",
    "    finisher = EmbeddingsFinisher() \\\n",
    "              .setInputCols(\"embeddings\") \\\n",
    "              .setOutputCols(\"embeddings_result\")\n",
    "\n",
    "    bert_pipeline = Pipeline(stages=[documentAssembler, embeddings, finisher])\n",
    "\n",
    "    df_bert = bert_pipeline.fit(df).transform(df) \\\n",
    "                         .select(col('comment'), col('label').cast(FloatType()), explode(\"embeddings_result\").alias('features')) \\\n",
    "                         .select(['comment'] + ['label'] + [expr('features[' + str(x) + ']') for x in range(768)])\n",
    "\n",
    "    ### VectorAssembler ###\n",
    "    vector_assembler = VectorAssembler(inputCols=df_bert.columns[2:], outputCol='features').setHandleInvalid(\"skip\")\n",
    "\n",
    "    features_assembled = vector_assembler.transform(df_bert).select('comment', 'features', 'label')\n",
    "\n",
    "    df_bert.unpersist()\n",
    "    del df_bert\n",
    "\n",
    "    print(\"Dataframe schema:\")\n",
    "    features_assembled.printSchema()\n",
    "\n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "    if save_parquet:\n",
    "        path_parquet = \"bert_sentence_features.parquet\"\n",
    "        features_assembled.write.mode(\"overwrite\").parquet(path_parquet)\n",
    "\n",
    "    return features_assembled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aK_hlfXgywH8"
   },
   "source": [
    "### Split dataset\n",
    "Split original dataset into 2 subdatasets: training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWVFXzRpEIJz"
   },
   "outputs": [],
   "source": [
    "def data_split(df_features):\n",
    "    print(\"Dataframe size in data_split: {:d} instances\".format(df_features.count()))\n",
    "\n",
    "    # Randomly split our original dataset into 80÷20 for training and test, respectively\n",
    "    train_df, test_df = df_features.randomSplit([0.8, 0.2], seed = 42)\n",
    "\n",
    "    df_features.unpersist()\n",
    "    del df_features\n",
    "\n",
    "    print(\"Training set size: {:d} instances\".format(train_df.count()))\n",
    "    print(\"Test set size: {:d} instances\".format(test_df.count()))\n",
    "\n",
    "    print(\"\\nLet's verify our datasets are still balanced:\")\n",
    "    train_df.groupBy('label').count().show()\n",
    "    test_df.groupBy('label').count().show()\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF5vgp3FwhWZ"
   },
   "source": [
    "## **Classification models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZSKaQYZwnyB"
   },
   "source": [
    "### **Logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvELNZT6xNnK"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUb40P1j9U_i"
   },
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(train_df, test_df, suffix_path=\"\", save_model=False):\n",
    "\n",
    "    lr = LogisticRegression(featuresCol='features',\n",
    "                          labelCol='label',\n",
    "                          maxIter=100,\n",
    "                          regParam=0.3,\n",
    "                          elasticNetParam=0.8)\n",
    "\n",
    "    ### Search for the best model's parameters. ###\n",
    "\n",
    "    # We use a ParamGridBuilder to construct a grid of parameters to search over\n",
    "    param_grid = ParamGridBuilder() \\\n",
    "                .addGrid(lr.regParam, [0.0, 0.05, 0.1]) \\\n",
    "                .addGrid(lr.elasticNetParam, [0.5, 0.8, 1.0]) \\\n",
    "                .build()\n",
    "\n",
    "    cross_val = CrossValidator(estimator=lr,\n",
    "                             estimatorParamMaps=param_grid,\n",
    "                             evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"),\n",
    "                             numFolds=5,\n",
    "                             parallelism=5)\n",
    "\n",
    "    # Run cross-validation, and choose the best set of parameters.\n",
    "    cv_model = cross_val.fit(train_df)\n",
    "\n",
    "    best_lr = cv_model.bestModel\n",
    "\n",
    "    print(\"--- Best model's parameters: ---\\n- reParam = {:f}\\n- elasticNetParam = {:f}\".format(best_lr.getRegParam(), best_lr.getElasticNetParam()))\n",
    "\n",
    "    lr_predictions = best_lr.transform(test_df)\n",
    "    lr_prediction.show(10)\n",
    "\n",
    "    if save_model:\n",
    "        path = \"models/logisticRegression_\" + suffix_path\n",
    "        best_lr.write().overwrite().save(path)\n",
    "\n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "    return lr_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcQEUTaFmYBV"
   },
   "source": [
    "### **Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDWYCPMsmhHj"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dIqrNFXiiJR"
   },
   "outputs": [],
   "source": [
    "def random_forest_classifier(train_df, test_df, suffix_path='', save_model=False):\n",
    "\n",
    "    rf = RandomForestClassifier(featuresCol='features',\n",
    "                              labelCol='label')\n",
    "\n",
    "    ### Search for the best model's parameters. ###\n",
    "\n",
    "    # We use a ParamGridBuilder to construct a grid of parameters to search over\n",
    "    param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [3, 5, 8]) \\\n",
    "    .addGrid(rf.numTrees, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "    cross_val = CrossValidator(estimator=rf,\n",
    "                             estimatorParamMaps=param_grid,\n",
    "                             evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"),\n",
    "                             numFolds=5,\n",
    "                             parallelism=5)\n",
    "\n",
    "    # Run cross-validation, and choose the best set of parameters.\n",
    "    cv_model = cross_val.fit(train_df)\n",
    "\n",
    "    best_rf = cv_model.bestModel\n",
    "\n",
    "    print(\"--- Best model's parameters: ---\\n- maxDepth = {:d}\\n- numTrees = {:d}\".format(best_rf.getMaxDepth(), best_rf.getNumTrees()))\n",
    "\n",
    "    rf_predictions = best_rf.transform(test_df)\n",
    "    rf_predictions.show(10)\n",
    "\n",
    "    if save_model:\n",
    "        path = \"models/randomForest_\" + suffix_path\n",
    "        best_rf.write().overwrite().save(path)\n",
    "\n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "    return rf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyj7FtWimhir",
    "tags": []
   },
   "source": [
    "### **Linear Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjmtSKKXmlw_"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ic7Yzu_BdsH7"
   },
   "outputs": [],
   "source": [
    "def linear_svc_classifier(train_df, test_df, suffix_path='', save_model=False):\n",
    "\n",
    "    lsvc = LinearSVC(featuresCol='features', labelCol='label',\n",
    "                   maxIter=10, regParam=0.1)\n",
    "\n",
    "    ### Search for the best model's parameters. ###\n",
    "\n",
    "    # We use a ParamGridBuilder to construct a grid of parameters to search over\n",
    "    param_grid = ParamGridBuilder() \\\n",
    "                .addGrid(lsvc.regParam, [0.0, 0.05, 0.1]) \\\n",
    "                .addGrid(lsvc.maxIter, [50, 100]) \\\n",
    "                .build()\n",
    "\n",
    "    cross_val = CrossValidator(estimator=lsvc,\n",
    "                             estimatorParamMaps=param_grid,\n",
    "                             evaluator=BinaryClassificationEvaluator(metricName=\"areaUnderROC\"),\n",
    "                             numFolds=5,\n",
    "                             parallelism=5)\n",
    "\n",
    "    # Run cross-validation, and choose the best set of parameters.\n",
    "    cv_model = cross_val.fit(train_df)\n",
    "\n",
    "    best_lsvc = cv_model.bestModel\n",
    "\n",
    "    print(\"--- Best model's parameters: ---\\n- regParam = {:f}\\n- maxIter = {:d}\".format(best_lsvc.getRegParam(), best_lsvc.getMaxIter()))\n",
    "\n",
    "    lsvc_predictions = best_lsvc.transform(test_df)\n",
    "    lsvc_predictions.show(10)\n",
    "\n",
    "    if save_model:\n",
    "        path = \"models/linearSVC_\" + suffix_path\n",
    "        best_lsvc.write().overwrite().save(path)\n",
    "\n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "    return lsvc_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf8ZO9nTmlPQ"
   },
   "source": [
    "### **Multilayer perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaNVvY-8mqqp"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-qlmPpDLa0H"
   },
   "outputs": [],
   "source": [
    "def mlp_classifier(train_df, test_df, suffix_path='', save_model=False):\n",
    "\n",
    "    # specify layers for the neural network:\n",
    "    input_layer = 768 # features\n",
    "    output_layer = 2 # number of classes\n",
    "    layers = [input_layer, 64, 32, output_layer]\n",
    "\n",
    "    mlp = MultilayerPerceptronClassifier(featuresCol='features', labelCol='label',\n",
    "                                       maxIter=100, layers=layers, blockSize=256, seed=42)\n",
    "\n",
    "    mlp_model = mlp.fit(train_df)\n",
    "\n",
    "    print(\"--- Model's parameters: ---\\n- layers = {:s}\".format(str(mlp_model.getLayers())))\n",
    "\n",
    "    mlp_predictions = mlp_model.transform(test_df)\n",
    "    mlp_predictions.show(10)\n",
    "\n",
    "    if save_model:\n",
    "        path = \"models/mlp_\" + suffix_path\n",
    "        mlp_model.write().overwrite().save(path)\n",
    "\n",
    "    # garbage collector\n",
    "    gc.collect()\n",
    "\n",
    "    return mlp_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CN2C01Gx7Y14"
   },
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "178qa1FbMvcg"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuDinRMUp_QK"
   },
   "outputs": [],
   "source": [
    "def evaluation(model_predictions):\n",
    "    print(\"***** Test Set *****\")\n",
    "\n",
    "    preds_df = model_predictions.select(\"comment\", \"label\", \"prediction\").toPandas()\n",
    "\n",
    "    print(\"\\nShow some examples of miss-predictions: \")\n",
    "    display(preds_df[preds_df['prediction'] != preds_df['label']].head(100))\n",
    "\n",
    "    print(\"\\nClassification report:\")\n",
    "    clf_report = classification_report(y_true=preds_df['label'], y_pred=preds_df['prediction'], zero_division=0)\n",
    "    print(clf_report)\n",
    "\n",
    "    evaluator = BinaryClassificationEvaluator()\n",
    "    evaluator.setRawPredictionCol('rawPrediction')\n",
    "\n",
    "    # calculate AUROC\n",
    "    print('Area Under ROC Curve (AUROC): %.3f' % evaluator.evaluate(model_predictions, {evaluator.metricName: \"areaUnderROC\"}))\n",
    "\n",
    "    # calculate AUPR\n",
    "    print('Area Under Precision-Recall Curve (AUPR): %.3f' % evaluator.evaluate(model_predictions, {evaluator.metricName: \"areaUnderPR\"}))\n",
    "\n",
    "    # calculate MCC\n",
    "    print(\"Matthews Correlation Coefficient (MCC): \", matthews_corrcoef(preds_df['label'], preds_df['prediction']))\n",
    "\n",
    "    print(\"\\n***** Test Set *****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noKx6G_Gp-5S"
   },
   "source": [
    "## **Experiments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfPDzHzSKmWa"
   },
   "source": [
    "### Data loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3DxkBnx_KQj"
   },
   "outputs": [],
   "source": [
    "df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-HIQPRt_Ne8"
   },
   "outputs": [],
   "source": [
    "cleaned_df = clean_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dXv09wBm_fDU"
   },
   "outputs": [],
   "source": [
    "df.unpersist()\n",
    "del df\n",
    "\n",
    "print(\"Garbage collector: collected %d objects\" % (gc.collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oF_TSowrvKz",
    "tags": []
   },
   "source": [
    "### Models + BERT Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzyO0PF6CcUq"
   },
   "outputs": [],
   "source": [
    "# features_df_bert = spark.read.parquet(\"bert_sentence_features.parquet\")\n",
    "features_df_bert = bert_sentence_embedding(cleaned_df, save_parquet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-1tTAt1rvK0"
   },
   "outputs": [],
   "source": [
    "cleaned_df.unpersist()\n",
    "del cleaned_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RUn5X_hUFaiC"
   },
   "outputs": [],
   "source": [
    "train_df_bert, test_df_bert = data_split(features_df_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qo6RohTxrvK1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_df_bert.unpersist()\n",
    "del features_df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cb5S9viHFhly"
   },
   "outputs": [],
   "source": [
    "model_predictions = logistic_regression_classifier(train_df_bert, test_df_bert, \"BERT_sentence\")\n",
    "evaluation(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOhAs55Tkdcm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_predictions = random_forest_classifier(train_df_bert, test_df_bert, \"BERT_sentence\")\n",
    "evaluation(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2A6lv1zFVsfq"
   },
   "outputs": [],
   "source": [
    "model_predictions = linear_svc_classifier(train_df_bert, test_df_bert, \"BERT_sentence\")\n",
    "evaluation(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UnCvG3iVsyZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_predictions = mlp_classifier(train_df_bert, test_df_bert, \"BERT_sentence\", save_model=True)\n",
    "evaluation(model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MglfW9VPrvK5"
   },
   "outputs": [],
   "source": [
    "train_df_bert.unpersist()\n",
    "test_df_bert.unpersist()\n",
    "model_predictions.unpersist()\n",
    "\n",
    "del train_df_bert\n",
    "del test_df_bert\n",
    "del model_predictions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZF5vgp3FwhWZ"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
